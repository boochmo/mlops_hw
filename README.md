# mlops_hw

В качестве игрушечного проекта используется логистическая регрессия на Iris
датасете.

## Предварительно

1. Скопировать репозиторий
2. Создать виртуальное окружение
3. Находясь в репозитории и активировав виртуальное окружение, установить
   зависимости

```
poetry install
```

## Обучение

Для логирования необходимо поднять сервер `MLFlow`.

```
mlflow server --host 127.0.0.1 --port 8080
```

Либо другой адрес и порт, для чего необходимо поменять `train.mlflow_server` в
`iris_classifier/conf/config.yaml`.

Далее запустить скрипт обучения

```
python iris_classifier/train.py
```

По окончании выполнения появятся файлы модели в форматах `.sav` и `.onnx`, а
также результат от `MLFlow` в папке `model`. Также появятся графики результатов
валидации, они также все буду залогированы `MLFlow`.

## Инференс (локально)

Для локального инференса (как в первом домашнем задании):

```
python iris_classifier/infer.py
```

В результате будут выведен отчёт с метриками на тесте, а в репозитории появится
`predictions.csv` с предсказаниями на тестовой выборке.

## Инференс с MLFlow Models

Сначала необходимо поднять сервер для инференса.

```
mlflow models serve -m model --env-manager local --host 127.0.0.1
```

Если нужно поменять адрес или порт, перед этим так же нужно поменять конфиг
`infer.mlflow_server` в `iris_classifier/conf/config.yaml`. Далее запустить
скрипт

```
python iris_classifier/run_server.py
```

Скрипт отправит тестовый запрос на сервер, в ответ будет получен результат
работы в виде

```
{'output_label': 'virginica',
'output_probability': {
  'setosa': 0.0006740661920048296,
  'versicolor': 0.08054611086845398,
  'virginica': 0.9187798500061035
  }
}
```
